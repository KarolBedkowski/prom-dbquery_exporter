global:
  request_timeout: 600s
# sample database databases configuration
database:
  testdb:
    driver: sqlite
    # connection parameters
    connection:
      database: rwr3.db
    # pool configuration
    pool:
      # max number of active connection; default 10
      max_connections: 2
      # xax number of idle connection; default 1
      max_idle_connections: 1
      # connection max life time
      conn_max_life_time: 600s
    # additional labels that can be used in templates
    labels:
      env: test
    # initials query to run before any other queries
    initial_query:
      - select 1
    # default timeout for queries in second
    timeout: 1s
  testdbpgsql:
    driver: postgres
    connection:
      # postgresql may be configured with separate parameters
      database: postgres
      host: localhost
      user: dbquery_exporter
      password: dbquery_exporter
      port: 5432
    pool:
      max_connections: 3
      max_idle_connections: 1
    timeout: 60s
    background_workers: 1
  testdbpgsql2:
    driver: postgres
    connection:
      # postgresql connection may use connect string; other parameters
      # are ignored
      connstr: postgres://dbquery_exporter:dbquery_exporter@localhost/postgres
    pool:
      max_connections: 2
      max_idle_connections: 2
  testtib:
    driver: tidb
    connection:
      database: test
      host: localhost
      user: root
      password:
      port: 4000
  testoracle:
    driver: oci8
    connection:
      database: test
      host: 127.0.0.1
      user: testuser
      password: testpass#1
      port: 1521
    initial_query:
      - alter session set default_schema=test

# queries configuration.
# query is not bind direct to any database
query:
  ping:
    # query can belong to some group and all queries in group can be executed
    # on request
    groups:
      - pg
      - oracle
    sql: select 1
    # use current database name
    metrics: |
      ping{database="{{ .Database }}"} 1
    # this is returned on query error
    on_error: |
      ping{database="{{ .Database }}"} 0

  testq1:
    # Characters like `:` must be doubled to prevent binding parameters.
    sql: >
       select s.name, count(t.id) as cnt
       from sports s left join trips t on s.id = t.sport_id
       group by s.name

    # result of query is cached by 20 second
    caching_time: 20s
    # timeout define query timeout in second
    timeout: 1s
    # Rows from query are accessible via `context.R` variable and should be
    # always iterate.
    # Labels defined on database level are available via `context.L map`.
    # Some other variables are available:
    # `.Count` - total number of query result
    # `.QueryDuration` - query duration in sec
    # `.QueryStartTime` - start query as unix time (time of execution, even cached)
    metrics: |
      {{ $top := . }}
      {{- range .R }}
      rwr3_sport_trip_count{sport="{{ .name }}", dbname="{{ $top.L.env }}"} {{ .cnt }}
      {{- end  }}
      rwr3_sport_trip_count_rows {{ .Count }}
      rwr3_sport_trip_query_seconds {{ .QueryDuration }}
      rwr3_sport_trip_last_query_unix {{ .QueryStartTime }}

  testq2:
    sql: >
       select count(t.id) as cnt from trips t

    metrics: |
      {{- range .R }}
      rwr3_trips_count {{ .cnt }}
      {{- end  }}
      rwr3_trips_count_rows {{ .Count }}
      rwr3_trips_query_seconds {{ .QueryDuration }}
      rwr3_trips_last_query_unix {{ .QueryStartTime }}

  test_buckets:
    sql: >
       select sport_id, distance from trips t

    metrics: |
      {{- range (buckets .R "distance" 5.0 10.0 20.0 40.0 50.0) }}
      rwr3_trips_distance_bucket{sport_id="{{ .sport_id }}", le="{{ .le }}"} {{ .count }}
      {{- end  }}

  test_buckets_int:
    sql: >
       select sport_id, duration from trips t

    metrics: |
      {{- range (bucketsInt .R "duration" 3600 7200 10800 14400 18000) }}
      rwr3_trips_duration_bucket{sport_id="{{ .sport_id }}", le="{{ .le }}"} {{ .count }}
      {{- end  }}

  test_long_query:
    sql: >
      WITH RECURSIVE r(i) AS (
        VALUES(0)
        UNION ALL
        SELECT i FROM r
        LIMIT 10000000
      )
      SELECT i as v FROM r WHERE i = 1;
    metrics: |
      test_long_query 1
      {{- range .R }}
      test_res {{ .v }}
      {{- end  }}

  test_long_query_pg:
    sql: select pg_sleep(5 * 60);
    metrics: |
      test_long_query 2

  testparam1:
    # Queries may use parameters delivered by request->query (ie ...&id=12)
    sql: >
      select count(t.id) as cnt from trips t where id > :id

    # Parameters are accessible via `context.P` map
    metrics: |
      {{ $top := . }}
      {{- range .R }}
      rwr3_trips_count_limited{limit="{{ $top.P.id }}"} {{ .cnt }}
      {{- end  }}

    params:
      id: 0

  # real & useful databases queries

  pg_stats_activity_state:
    sql: >
      SELECT tmp.state as state, count(psa.state) AS cnt
      FROM (VALUES ('active'), ('idle'), ('idle in transaction'), ('idle in transaction (aborted)'), ('fastpath function call'), ('disabled')) AS tmp(state)
      LEFT JOIN pg_stat_activity psa ON psa.state = tmp.state
      GROUP BY tmp.state
    caching_time: 30s
    metrics: |
      {{- range .R }}
      pg_stats_activity_state{state="{{ .state }}"} {{ .cnt }}
      {{- end }}

  pg_stats_activity_state_db:
    sql: >
      WITH s AS (
        SELECT datname, state, count(*) AS cnt
        FROM pg_stat_activity
        GROUP BY datname, state
      )
      SELECT pd.datname, tmp.state, COALESCE(s.cnt, 0) as cnt
      FROM (VALUES ('active'), ('idle'), ('idle in transaction'), ('idle in transaction (aborted)'), ('fastpath function call'), ('disabled')) AS tmp(state)
      CROSS JOIN pg_database pd
      LEFT JOIN s ON s.state = tmp.state AND s.datname = pd.datname
    caching_time: 30s
    metrics: |
      {{- range .R }}
      pg_stats_activity_state_db{database="{{ .datname }}", state="{{ .state }}"} {{ .cnt }}
      {{- end }}

  pg_stat_database:
    groups:
      - pgstats
      - pg
    sql: >
      SELECT COALESCE(psd.datname, '') AS datname, numbackends, xact_commit,
        xact_rollback, blks_read, blks_hit, tup_returned, tup_fetched,
        tup_inserted, tup_updated, tup_deleted, conflicts, temp_files,
        temp_bytes, deadlocks, blk_read_time, blk_write_time,
        CASE WHEN (psd.blks_hit + blks_read) > 0
          THEN (cast(psd.blks_hit AS float) / (psd.blks_hit + psd.blks_read))
          ELSE 1.0
        END as cache_hit_ratio,
        CASE WHEN (xact_commit + xact_rollback) > 0
          THEN (CAST(xact_commit AS float) / (xact_commit + xact_rollback))
          ELSE 1.0
        END as commit_ratio,
        pg_database_size(psd.datname) AS size
      FROM pg_stat_database psd
      JOIN pg_database pd ON pd.oid =  psd.datid
      WHERE not pd.datistemplate
    caching_time: 30s
    metrics: |
      {{- range .R }}
      pg_stat_database_numbackends{name="{{.datname}}"} {{.numbackends}}
      pg_stat_database_xact_commit{name="{{.datname}}"} {{.xact_commit}}
      pg_stat_database_xact_rollback{name="{{.datname}}"} {{.xact_rollback}}
      pg_stat_database_blks_read{name="{{.datname}}"} {{.blks_read}}
      pg_stat_database_blks_hit{name="{{.datname}}"} {{.blks_hit}}
      pg_stat_database_tup_returned{name="{{.datname}}"} {{.tup_returned}}
      pg_stat_database_tup_fetched{name="{{.datname}}"} {{.tup_fetched}}
      pg_stat_database_tup_inserted{name="{{.datname}}"} {{.tup_inserted}}
      pg_stat_database_tup_updated{name="{{.datname}}"} {{.tup_updated}}
      pg_stat_database_tup_deleted{name="{{.datname}}"} {{.tup_deleted}}
      pg_stat_database_conflicts{name="{{.datname}}"} {{.conflicts}}
      pg_stat_database_temp_files{name="{{.datname}}"} {{.temp_files}}
      pg_stat_database_temp_bytes{name="{{.datname}}"} {{.temp_bytes}}
      pg_stat_database_deadlocks{name="{{.datname}}"} {{.deadlocks}}
      pg_stat_database_blk_read_time{name="{{.datname}}"} {{.blk_read_time}}
      pg_stat_database_blk_write_time{name="{{.datname}}"} {{.blk_write_time}}
      pg_stat_database_cache_hit_ratio{name="{{.datname}}"} {{.cache_hit_ratio}}
      pg_stat_database_commit_ratio{name="{{.datname}}"} {{.commit_ratio}}
      pg_database_size{name="{{.datname}}"} {{.size}}
      {{- end }}

  pg_stat_database_conflicts:
    groups:
      - pgstats
    sql: >
      SELECT psdc.datname, confl_tablespace, confl_lock, confl_snapshot,
        confl_bufferpin, confl_deadlock
      FROM pg_stat_database_conflicts psdc
      JOIN pg_database pd ON pd.oid =  psdc.datid
      WHERE not pd.datistemplate
    caching_time: 1m
    metrics: |
      {{- range .R }}
      pg_stat_database_conflicts{name="{{.datname}}", conf="tablespace"} {{.confl_tablespace}}
      pg_stat_database_conflicts{name="{{.datname}}", conf="lock"} {{.confl_lock}}
      pg_stat_database_conflicts{name="{{.datname}}", conf="snapshot"} {{.confl_snapshot}}
      pg_stat_database_conflicts{name="{{.datname}}", conf="bufferpin"} {{.confl_bufferpin}}
      pg_stat_database_conflicts{name="{{.datname}}", conf="deadlock"} {{.confl_deadlock}}
      {{- end }}

  pg_locks_db:
    groups:
      - pgstats
    sql: >
      WITH s AS (
        SELECT DATABASE, lower(MODE) AS mode, count(*) AS cnt
        FROM pg_locks
        WHERE DATABASE IS NOT null
        GROUP BY DATABASE, lower(MODE)
      )
      SELECT pd.datname, tmp.mode, COALESCE(s.cnt, 0) as cnt
      FROM (VALUES ('accesssharelock'), ('rowsharelock'), ('rowexclusivelock'), ('shareupdateexclusivelock'),  ('sharelock'),
        ('sharerowexclusivelock'), ('exclusivelock'),  ('accessexclusivelock'), ('sireadlock')) AS tmp(mode)
      CROSS JOIN pg_database pd
      LEFT JOIN s ON s.mode = tmp.MODE AND s.database = pd.oid
    caching_time: 1m
    metrics: |
      {{- range .R }}
      pg_locks{database="{{ .datname }}", mode="{{ .mode }}"} {{ .cnt }}
      {{- end }}

  pg_locks:
    groups:
      - pg
    sql: >
      SELECT tmp.mode, count(pl.mode) as cnt
      FROM (VALUES ('accesssharelock'), ('rowsharelock'), ('rowexclusivelock'), ('shareupdateexclusivelock'),  ('sharelock'),
        ('sharerowexclusivelock'), ('exclusivelock'),  ('accessexclusivelock'), ('sireadlock')) AS tmp(mode)
      LEFT JOIN pg_locks pl ON lower(pl.MODE) = tmp.MODE AND pl."database" IS NOT null
      GROUP BY tmp.MODE
    caching_time: 60s
    metrics: |
      {{- range .R }}
      pg_locks{mode="{{ .mode }}"} {{ .cnt }}
      {{- end }}

  # long running
  pg_tx:
    groups:
      - pgstats
    sql: >
      SELECT min(EXTRACT(EPOCH FROM xact_start)) AS oldesttx, count(*) AS cnt
      FROM pg_stat_activity
      WHERE state IS DISTINCT FROM 'idle' AND query NOT LIKE 'autovacuum%'
        AND xact_start IS NOT NULL
    metrics: |
      {{- range .R }}
      pg_tx_oldest {{ .oldesttx }}
      pg_tx_total {{ .cnt }}
      {{- end }}

  pg_db:
    groups:
      - pg
    sql: >
      SELECT 'postmaster_start_unix' AS name, '' AS key, EXTRACT(EPOCH FROM pg_postmaster_start_time) AS val FROM pg_postmaster_start_time()
      UNION ALL
      SELECT 'databases_count' as name, '' AS key, count(*) AS val FROM pg_database
      UNION ALL
      SELECT 'version' as name, version() as key, 1 as val
    metrics: |
      {{- range .R }}
        {{- if (ne .key "") }}
          pg_db_{{ .name }}{key="{{ .key | removeQuotes }}"} {{ .val }}
        {{- else }}
          pg_db_{{ .name }} {{ .val }}
        {{- end }}
      {{- end }}

  pg_wal:
    groups:
      - pg
    sql: >
      SELECT count(*) AS segments, sum(size) AS size
      FROM pg_ls_waldir()
      WHERE name ~ '^[0-9A-F]{24}$'
    metrics: |
      {{- range .R }}
      pg_wal_size_bytes {{ .size }}
      pg_wal_segments {{ .segments }}
      {{- end }}

  pg_statio_user_tables:
    groups:
      - pg
    sql: >
      SELECT current_database() datname,
        schemaname, relname,
        heap_blks_read, heap_blks_hit, idx_blks_read, idx_blks_hit,
        toast_blks_read, toast_blks_hit, tidx_blks_read, tidx_blks_hit
      FROM pg_statio_user_tables
    metrics: |
      {{- range .R }}
      pg_statio_user_tables_heap_blocks_read{datname="{{ .datname }}",schemaname="{{ .schemaname }}",relname="{{ .relname }}"} {{ .heap_blks_read }}
      pg_statio_user_tables_heap_blocks_hit{datname="{{ .datname }}",schemaname="{{ .schemaname }}",relname="{{ .relname }}"} {{ .heap_blks_hit }}
      pg_statio_user_tables_idx_blocks_read{datname="{{ .datname }}",schemaname="{{ .schemaname }}",relname="{{ .relname }}"} {{ .idx_blks_read }}
      pg_statio_user_tables_idx_blocks_hit{datname="{{ .datname }}",schemaname="{{ .schemaname }}",relname="{{ .relname }}"} {{ .idx_blks_hit }}
      pg_statio_user_tables_toast_blocks_read{datname="{{ .datname }}",schemaname="{{ .schemaname }}",relname="{{ .relname }}"} {{ .toast_blks_read }}
      pg_statio_user_tables_toast_blocks_hit{datname="{{ .datname }}",schemaname="{{ .schemaname }}",relname="{{ .relname }}"} {{ .toast_blks_hit }}
      pg_statio_user_tables_tidx_blocks_read{datname="{{ .datname }}",schemaname="{{ .schemaname }}",relname="{{ .relname }}"} {{ .tidx_blks_read }}
      pg_statio_user_tables_tidx_blocks_hit{datname="{{ .datname }}",schemaname="{{ .schemaname }}",relname="{{ .relname }}"} {{ .tidx_blks_hit }}
      {{- end }}

  pg_statio_user_indexes:
    groups:
      - pg
    sql: >
      SELECT schemaname, relname, indexrelname, idx_blks_read, idx_blks_hit FROM pg_statio_user_indexes
    metrics: |
      {{- range .R }}
      pg_statio_user_indexes_idx_blks_read_total{schemaname="{{ .schemaname }}",relname="{{ .relname }}",indexrelname="{{ .indexrelname }}"} {{ .idx_blks_read }}
      pg_statio_user_indexes_idx_blks_hit_total{schemaname="{{ .schemaname }}",relname="{{ .relname }}",indexrelname="{{ .indexrelname }}"} {{ .idx_blks_hit }}
      {{- end }}


  oracle_v_sysmetric:
    groups:
      - oracle
    sql: >
       select metric_name as name, to_char(value) as value
       from V$SYSMETRIC
       where GROUP_ID=2
    caching_time: 10s

    # some additional functions may be used for preparing result
    metrics: |
      {{- range .R }}
      oracle_v_sysmetric_{{ .NAME | keepAlfaNumUnderlineSpace | trim | replaceSpaces | toLower }} {{ .VALUE }}
      {{- end  }}

  # for tests
  pg_long_query:
    sql: >
        select pg_sleep(60)
    metrics: |
      pg_long_query_result 1

# run this queries in background and fill the cache
jobs:
  - query: pg_locks
    database: testdbpgsql
    interval: 30s
  - query: pg_locks_db
    database: testdbpgsql
    interval: 15s
  - query: pg_long_query
    database: testdbpgsql
    interval: 30s
